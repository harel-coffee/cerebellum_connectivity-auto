{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# “Software” Requirement Specifications\n",
    "The package is intended to evaluate predictions by different connectivity models and plot evaluation measures. It should have interfaces that enable the user to read and write data in MATLAB format and also gifti files. \n",
    "\n",
    "## Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Integration Module\n",
    "Should be able to work with MATLAB’s .mat files and gifti files.\n",
    "* Read in MATLAB’s .mat file\n",
    "    * Model’s input data used for prediction. Can be a structure with all the possible input data:\n",
    "        * Activity profiles\n",
    "        * Time series\n",
    "            * Predicted\n",
    "            * Residual\n",
    "            * Raw\n",
    "    * <font color = 'red'>Model’s output data structures for models created in MATLAB.<font color = 'black'>\n",
    "* Read in gifti formats to create cortical and cerebellar maps.\n",
    "\n",
    "#### How to load in MATLAB’s structures (saved as .mat files) into python?\n",
    "* Using python’s Matlab engine. Follow the instructions in https://www.mathworks.com/help/matlab/matlab_external/install-the-matlab-engine-for-python.html\n",
    "* mat73 package seems to be working for .mat files saved with '-v7.3'\n",
    "    * Pros: Works really good for -v7.3\n",
    "    * Cons: Works __only__ for version 7.3\n",
    "* scipy.io loadmat .mat files saved with versions before -7.3\n",
    "    \n",
    "#### List of functions:\n",
    "<font color = 'green'>__matImport__:<font color = 'black'>\n",
    "* Import mat files saved with v7.3 or before\n",
    "* Cannot import SPM.mat files saved with v7.3\n",
    "* Can handle nested structures\n",
    "    \n",
    "<font color = 'green'>__giftiImport__:<font color = 'black'>\n",
    "* Import gifti files\n",
    "* Uses nibabel\n",
    "** not even sure if we need it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation Module\n",
    "preparing input data for the modelling and evaluation pipelines.\n",
    "\n",
    "Check the comment section of each function for the description of the nested dictionaries' hierarchy\n",
    "\n",
    "#### List of functions:\n",
    "<font color = 'green'>__get_data__:<font color = 'black'>\n",
    "* get and prepares data for modelling\n",
    "* returns a nested dictionary:\n",
    "    * B_dict{experiment:{subject:{session:B_sess} }}\n",
    "* saves B_dict\n",
    "    \n",
    "<font color = 'green'>__get_wcon__:<font color = 'black'>\n",
    "* uses the data saved in get_data and the text file created to prepare the data for modelling\n",
    "\n",
    "##### Package dependencies:\n",
    "* pickle: for saving and loading the saved .dat files. \n",
    "    * pip install pickle-mixin \n",
    "    * pip3 install pickle-mixin\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling Module\n",
    "implements different models:\n",
    "* Ridge regression\n",
    "* principal component regression\n",
    "* partial least squares (projection to latent structure) regression\n",
    "* simultaneous parameter learning and biclustering for multi-response models:https://www.frontiersin.org/articles/10.3389/fdata.2019.00027/full\n",
    "\n",
    "\n",
    "#### List of functions:\n",
    "<font color = 'green'>__connect_fit__:<font color = 'black'>\n",
    "* used for fitting different models\n",
    "* uses sklearn FOR NOW!\n",
    "* Also calculates R2, R, R2_vox, R_vox\n",
    "* STILL UNDER CONSTRUCTION::Things to do:\n",
    "    * add simultaneous parameter estimation and biclustering method\n",
    "    * modify the pls regression method to model \"non-one-to-one\" connections\n",
    "    \n",
    "<font color = 'green'>__model_fit__:<font color = 'black'>\n",
    "* Uses connect_fit to fit models to data for each subject\n",
    "* saves a dictionary with all the model info\n",
    "    \n",
    "##### Package dependencies:\n",
    "* sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Essentials Module\n",
    "will contain functions used in other modules (preparation, modelling, and evaluation).\n",
    "List of functions (will be updated):\n",
    "* indicatorMatrix (translated indicatorMatrix.m into python)\n",
    "\n",
    "#### List of functions:\n",
    "<font color = 'green'>__indicatorMatrix__:<font color = 'black'>\n",
    "* translated code from MATLAB\n",
    "* STILL UNDER CONSTRUCTION!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Module\n",
    "Uses test data __(usually from sc2)__ and the model structure data to evaluate the predictions by the model. \n",
    "Cross-validation: calculates R2cv, Rcv, R2, R, and the voxel level measures + noise ceilings sparsity measures\n",
    "* Cross-validation within each subject:\n",
    "    * Sessions as folds\n",
    "    * Studies as folds\n",
    "    * Cross-validation with each subject as a fold. In case we decide to do the modelling at the group level.\n",
    "* Evaluation measures:\n",
    "    * Using all the conditions:\n",
    "        * Double cross-validated predictive correlation\n",
    "        * Not double-cross-validated predictive correlation\n",
    "        * Reliability of data \n",
    "        * Reliability of predictions\n",
    "        * Sparseness measures\n",
    "        * Upper noise ceiling\n",
    "        * Lower noise ceiling\n",
    "        * RDMs with the predicted data!\n",
    "    * Using the shared conditions only:\n",
    "        * Double cross-validated predictive correlation\n",
    "        * Not double-cross-validated predictive correlation\n",
    "        * Reliability of data \n",
    "        * Reliability of predictions\n",
    "        * Sparseness measures\n",
    "        * Upper noise ceiling\n",
    "        * Lower noise ceiling\n",
    "        * RDMs with the predicted data!\n",
    "* Make an integrated data structure with the data for all the models and all the subjects\n",
    "* Evaluation plots:\n",
    "    * Model evaluation measures vs parameters\n",
    "    * Cerebellar maps for voxel-wise measures.\n",
    "    \n",
    "#### List of functions:\n",
    "<font color = 'green'>__evaluate_model__:<font color = 'black'>\n",
    "* either crossed or uncrossed evaluation\n",
    "* STILL UNDER CONSTRUCTION::Things to do::\n",
    "    * use X'X to weight \n",
    "    * more flexible coding to use subsets of conditions\n",
    "    * plottings and maps\n",
    "    \n",
    "<font color = 'green'>__evaluate_pipeline__:<font color = 'black'>\n",
    "* evaluates multiple models for multiple subjects\n",
    "    \n",
    "<font color = 'green'>__eval_df__:<font color = 'black'>\n",
    "* creates a dataframe of all the available modelling and eval. info\n",
    "    \n",
    "#### Package dependencies:\n",
    "* sklearn\n",
    "* pickle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data types for saving\n",
    "In the pipeline, we will need to save some variables. \n",
    "* What is the proper type to save the variables? Dictionaries maybe? \n",
    "* What package do we need for saving?\n",
    "    * pickle is one of the recommended packages: pip install pickle-mixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
